{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parameter_Optimisation_Multinomial_Logistic_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victoriaporter58/Computational-techniques-for-recognising-handwritten-digits/blob/master/Parameter_Optimisation_Multinomial_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ha7EsyyEaT3"
      },
      "source": [
        "pip install tensorflow==1.14"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA_5F8v9bzXq"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as mpimg\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from datetime import datetime\n",
        "\n",
        "# import and read the MNIST dataset\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HwpLYdbipOX"
      },
      "source": [
        "pip freeze > requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWeI9hzuisjq"
      },
      "source": [
        "cat requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GswqpTubkeHx"
      },
      "source": [
        "# import and read the MNIST dataset\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_data')\n",
        "\n",
        "# set-up dataset as numpy array\n",
        "# seperate the dataset into training (60,000) images & labels and testing (10,000) images & labels\n",
        "train_images = np.asarray(mnist.train.images)\n",
        "train_labels = np.asarray(mnist.train.labels)\n",
        "test_images = np.asarray(mnist.test.images)\n",
        "test_labels = np.asarray(mnist.test.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Goc4UM0CUmt",
        "outputId": "d02d968e-0a25-4af8-aa41-71f3d5c36c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "hyperparameters = [\n",
        "    ['saga',0.5,1,'l2'],\n",
        "]\n",
        "\n",
        "for i in range(len(hyperparameters)):\n",
        "    print(\"Hyperparameter set: \",i+1)\n",
        "    for j in range(3):\n",
        "        clf = LogisticRegression(\n",
        "            multi_class='multinomial',\n",
        "            solver=hyperparameters[i][0],\n",
        "            C=hyperparameters[i][1],\n",
        "            tol=hyperparameters[i][2],\n",
        "            penalty=hyperparameters[i][3],\n",
        "        )\n",
        "\n",
        "        print(\"Run: \",j+1)\n",
        "\n",
        "        # Train on the entire dataset\n",
        "        start_train_time = datetime.now()\n",
        "        clf.fit(train_images,train_labels)\n",
        "        end_train_time = datetime.now()\n",
        "        print('Training complete:',end_train_time-start_train_time)\n",
        "\n",
        "        # Test on 10000 images:\n",
        "        test_x = test_images[:10000]\n",
        "        expected = test_labels[:10000].tolist()\n",
        "\n",
        "        start_test_time = datetime.now()\n",
        "        predicted = clf.predict(test_x)\n",
        "        end_test_time = datetime.now()\n",
        "\n",
        "        print(\"Accuracy: \", accuracy_score(expected, predicted))\n",
        "        print(\"Testing time:\", end_test_time-start_test_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hyperparameter set:  1\n",
            "Run:  1\n",
            "Training complete: 0:00:02.890687\n",
            "Accuracy:  0.9193\n",
            "Testing time: 0:00:00.019315\n",
            "Run:  2\n",
            "Training complete: 0:00:02.892041\n",
            "Accuracy:  0.9157\n",
            "Testing time: 0:00:00.018704\n",
            "Run:  3\n",
            "Training complete: 0:00:02.884093\n",
            "Accuracy:  0.9188\n",
            "Testing time: 0:00:00.019125\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
